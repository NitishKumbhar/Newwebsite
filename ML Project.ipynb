{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974af8fb",
   "metadata": {},
   "source": [
    "# IPL Score Prediction using Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601196e0",
   "metadata": {},
   "source": [
    "Since the dawn of the IPL in 2008, it has attracted viewers all around the globe. A high level of uncertainty and last moment nail biters has urged fans to watch the matches. Within a short period, IPL has become the highest revenue-generating league of cricket. In a cricket match, we often see the scoreline showing the probability of the team winning based on the current match situation. This prediction is usually done with the help of Data Analytics. Before when there were no advancements in machine learning, the prediction was usually based on intuitions or some basic algorithms. The above picture clearly tells you how bad is taking run rate as a single factor to predict the final score in a limited-overs cricket match. \n",
    "\n",
    "Being a cricket fan, visualizing the statistics of cricket is mesmerizing. We went through various blogs and found out patterns that could be used for predicting the score of IPL matches beforehand. \n",
    "\n",
    "# Tools used:\n",
    "Jupyter Notebook / Google colab\n",
    "Visual Studio\n",
    "# Technology used:\n",
    "Machine Learning.\n",
    "Deep Learning\n",
    "Flask (Front-end integration).\n",
    "Well, for the smooth running of the project we’ve used few libraries like NumPy, Pandas, Scikit-learn, TensorFlow, and Matplotlib.\n",
    "\n",
    "First, let’s import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b28859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea08420",
   "metadata": {},
   "source": [
    "Step 2: Data cleaning and formatting\n",
    "\n",
    "We imported both the datasets using .read_csv() method into a dataframe \n",
    "using pandas and displayed the first 5 rows of each dataset. We did some \n",
    "changes to our dataset like added a new column named “y” which had the runs\n",
    "scored in the first 6 overs from that particular inning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9719ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>match_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>innings</th>\n",
       "      <th>ball</th>\n",
       "      <th>batting_team</th>\n",
       "      <th>bowling_team</th>\n",
       "      <th>striker</th>\n",
       "      <th>non_striker</th>\n",
       "      <th>bowler</th>\n",
       "      <th>runs_off_bat</th>\n",
       "      <th>extras</th>\n",
       "      <th>wicket_type</th>\n",
       "      <th>player_dismissed</th>\n",
       "      <th>run</th>\n",
       "      <th>wickets</th>\n",
       "      <th>truns</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>335982</td>\n",
       "      <td>M Chinnaswamy Stadium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>SC Ganguly</td>\n",
       "      <td>BB McCullum</td>\n",
       "      <td>P Kumar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>335982</td>\n",
       "      <td>M Chinnaswamy Stadium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>BB McCullum</td>\n",
       "      <td>SC Ganguly</td>\n",
       "      <td>P Kumar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>335982</td>\n",
       "      <td>M Chinnaswamy Stadium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>BB McCullum</td>\n",
       "      <td>SC Ganguly</td>\n",
       "      <td>P Kumar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>335982</td>\n",
       "      <td>M Chinnaswamy Stadium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>BB McCullum</td>\n",
       "      <td>SC Ganguly</td>\n",
       "      <td>P Kumar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>335982</td>\n",
       "      <td>M Chinnaswamy Stadium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>BB McCullum</td>\n",
       "      <td>SC Ganguly</td>\n",
       "      <td>P Kumar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  match_id                  venue  innings  ball  \\\n",
       "0           0    335982  M Chinnaswamy Stadium        1   0.1   \n",
       "1           1    335982  M Chinnaswamy Stadium        1   0.2   \n",
       "2           2    335982  M Chinnaswamy Stadium        1   0.3   \n",
       "3           3    335982  M Chinnaswamy Stadium        1   0.4   \n",
       "4           4    335982  M Chinnaswamy Stadium        1   0.5   \n",
       "\n",
       "            batting_team                 bowling_team      striker  \\\n",
       "0  Kolkata Knight Riders  Royal Challengers Bangalore   SC Ganguly   \n",
       "1  Kolkata Knight Riders  Royal Challengers Bangalore  BB McCullum   \n",
       "2  Kolkata Knight Riders  Royal Challengers Bangalore  BB McCullum   \n",
       "3  Kolkata Knight Riders  Royal Challengers Bangalore  BB McCullum   \n",
       "4  Kolkata Knight Riders  Royal Challengers Bangalore  BB McCullum   \n",
       "\n",
       "   non_striker   bowler  runs_off_bat  extras wicket_type player_dismissed  \\\n",
       "0  BB McCullum  P Kumar           0.0     1.0                                \n",
       "1   SC Ganguly  P Kumar           0.0     0.0                                \n",
       "2   SC Ganguly  P Kumar           0.0     1.0                                \n",
       "3   SC Ganguly  P Kumar           0.0     0.0                                \n",
       "4   SC Ganguly  P Kumar           0.0     0.0                                \n",
       "\n",
       "   run  wickets  truns     y  \n",
       "0  1.0      0.0    1.0  68.0  \n",
       "1  0.0      0.0    1.0  68.0  \n",
       "2  1.0      0.0    2.0  68.0  \n",
       "3  0.0      0.0    2.0  68.0  \n",
       "4  0.0      0.0    2.0  68.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipl = pd.read_csv('0y clean data pre ipl.csv')\n",
    "ipl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576a094d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Batting Innings</th>\n",
       "      <th>Not Out</th>\n",
       "      <th>Runds Scored</th>\n",
       "      <th>Highest Score</th>\n",
       "      <th>Batting Average</th>\n",
       "      <th>Balls Faced</th>\n",
       "      <th>...</th>\n",
       "      <th>Runs Conceded</th>\n",
       "      <th>Wickets Taken</th>\n",
       "      <th>Best Bowling Figures</th>\n",
       "      <th>Bowling Average</th>\n",
       "      <th>Bowling Economy Rate</th>\n",
       "      <th>Bowling Strike Rate</th>\n",
       "      <th>4+ Innings Wickets</th>\n",
       "      <th>5+ Innings Wickets</th>\n",
       "      <th>Catches Taken</th>\n",
       "      <th>Stumpings Made</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>CH Morris</td>\n",
       "      <td>IPL 2016</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>195</td>\n",
       "      <td>82*</td>\n",
       "      <td>65.00</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>308</td>\n",
       "      <td>13</td>\n",
       "      <td>2/30</td>\n",
       "      <td>23.69</td>\n",
       "      <td>7.00</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>CH Morris</td>\n",
       "      <td>IPL 2017</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>52*</td>\n",
       "      <td>30.80</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>12</td>\n",
       "      <td>4/26</td>\n",
       "      <td>20.00</td>\n",
       "      <td>7.74</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>CH Morris</td>\n",
       "      <td>IPL 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>27*</td>\n",
       "      <td>46.00</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>2/41</td>\n",
       "      <td>47.66</td>\n",
       "      <td>10.21</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>JP Duminy</td>\n",
       "      <td>IPL 2016</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>49*</td>\n",
       "      <td>38.20</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1/4</td>\n",
       "      <td>27.50</td>\n",
       "      <td>7.85</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>Q de Kock</td>\n",
       "      <td>IPL 2016</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>108</td>\n",
       "      <td>37.08</td>\n",
       "      <td>327</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Team     Player Tournament  Matches Batting Innings Not Out  \\\n",
       "0  Delhi Daredevils  CH Morris   IPL 2016       12               7       4   \n",
       "1  Delhi Daredevils  CH Morris   IPL 2017        9               9       4   \n",
       "2  Delhi Daredevils  CH Morris   IPL 2018        4               4       3   \n",
       "3  Delhi Daredevils  JP Duminy   IPL 2016       10               8       3   \n",
       "4  Delhi Daredevils  Q de Kock   IPL 2016       13              13       1   \n",
       "\n",
       "  Runds Scored Highest Score Batting Average Balls Faced  ... Runs Conceded  \\\n",
       "0          195           82*           65.00         109  ...           308   \n",
       "1          154           52*           30.80          94  ...           240   \n",
       "2           46           27*           46.00          26  ...           143   \n",
       "3          191           49*           38.20         156  ...            55   \n",
       "4          445           108           37.08         327  ...             -   \n",
       "\n",
       "  Wickets Taken Best Bowling Figures Bowling Average Bowling Economy Rate  \\\n",
       "0            13                 2/30           23.69                 7.00   \n",
       "1            12                 4/26           20.00                 7.74   \n",
       "2             3                 2/41           47.66                10.21   \n",
       "3             2                  1/4           27.50                 7.85   \n",
       "4             -                    -               -                    -   \n",
       "\n",
       "  Bowling Strike Rate 4+ Innings Wickets 5+ Innings Wickets Catches Taken  \\\n",
       "0                20.3                  0                  0             8   \n",
       "1                15.5                  1                  0             5   \n",
       "2                28.0                  0                  0             2   \n",
       "3                21.0                  0                  0             3   \n",
       "4                   -                  -                  -             2   \n",
       "\n",
       "  Stumpings Made  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IPL Player Stats - 2016 till 2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd6754",
   "metadata": {},
   "source": [
    "Now, we will merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1908c136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['venue', 'innings', 'ball', 'batting_team', 'bowling_team', 'striker',\n",
       "       'non_striker', 'bowler', 'run', 'wickets', 'truns', 'y', 'Team',\n",
       "       'Player', 'Tournament', 'Matches', 'Batting Innings', 'Not Out',\n",
       "       'Runds Scored', 'Highest Score', 'Batting Average', 'Balls Faced',\n",
       "       'Batting Strike Rate', '100', '50', '0', '4s', '6s', 'Bowling Innings',\n",
       "       'Overs Bowled', 'Maidens Bowled', 'Runs Conceded', 'Wickets Taken',\n",
       "       'Best Bowling Figures', 'Bowling Average', 'Bowling Economy Rate',\n",
       "       'Bowling Strike Rate', '4+ Innings Wickets', '5+ Innings Wickets',\n",
       "       'Catches Taken', 'Stumpings Made'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipl= ipl.drop(['Unnamed: 0','extras','match_id', 'runs_off_bat'],axis = 1)\n",
    "new_ipl = pd.merge(ipl,data,left_on='striker',right_on='Player',how='left')\n",
    "new_ipl.drop(['wicket_type', 'player_dismissed'],axis=1,inplace=True)\n",
    "new_ipl.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85feb0b",
   "metadata": {},
   "source": [
    "After merging the columns and removing new unwanted columns, we have the following columns left. Here’s the modified dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e264023",
   "metadata": {},
   "source": [
    "There are various ways to fill null values in our dataset. Here I am simply replacing the categorical values which are nan with ‘.’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8da914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = new_ipl.columns[new_ipl.dtypes==object]\n",
    "new_ipl[str_cols] = new_ipl[str_cols].fillna('.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691ca4c",
   "metadata": {},
   "source": [
    "Step 3: Encoding the categorical data to numerical values.\n",
    "\n",
    "For the columns to be able to assist the model in the prediction, the values should make some sense to the computers. Since they (still) don’t have the ability to understand and draw inferences from the text, we need to encode the strings to numeric categorical values. While we may choose to do the process manually, the Scikit-learn library gives us an option to use LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530722d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listf = []\n",
    "  \n",
    "for c in new_ipl.columns:\n",
    "    if new_ipl.all==object:\n",
    "        print(c,\"->\" ,new_ipl.dtype)\n",
    "        listf.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6a5ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>innings</th>\n",
       "      <th>ball</th>\n",
       "      <th>batting_team</th>\n",
       "      <th>bowling_team</th>\n",
       "      <th>striker</th>\n",
       "      <th>non_striker</th>\n",
       "      <th>bowler</th>\n",
       "      <th>run</th>\n",
       "      <th>wickets</th>\n",
       "      <th>...</th>\n",
       "      <th>Runs Conceded</th>\n",
       "      <th>Wickets Taken</th>\n",
       "      <th>Best Bowling Figures</th>\n",
       "      <th>Bowling Average</th>\n",
       "      <th>Bowling Economy Rate</th>\n",
       "      <th>Bowling Strike Rate</th>\n",
       "      <th>4+ Innings Wickets</th>\n",
       "      <th>5+ Innings Wickets</th>\n",
       "      <th>Catches Taken</th>\n",
       "      <th>Stumpings Made</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>186</td>\n",
       "      <td>30</td>\n",
       "      <td>201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>184</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>184</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>184</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>184</td>\n",
       "      <td>201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85186</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>47</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85187</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>47</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85188</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>126</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85189</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>126</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85190</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>126</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85191 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       venue  innings  ball  batting_team  bowling_team  striker  non_striker  \\\n",
       "0         15        1   0.1             7            13      186           30   \n",
       "1         15        1   0.2             7            13       30          184   \n",
       "2         15        1   0.2             7            13       30          184   \n",
       "3         15        1   0.2             7            13       30          184   \n",
       "4         15        1   0.3             7            13       30          184   \n",
       "...      ...      ...   ...           ...           ...      ...          ...   \n",
       "85186     31        1   6.5            14            10      127           47   \n",
       "85187     31        1   6.5            14            10      127           47   \n",
       "85188     31        1   6.6            14            10       48          126   \n",
       "85189     31        1   6.6            14            10       48          126   \n",
       "85190     31        1   6.6            14            10       48          126   \n",
       "\n",
       "       bowler  run  wickets  ...  Runs Conceded  Wickets Taken  \\\n",
       "0         201  1.0      0.0  ...              1              1   \n",
       "1         201  0.0      0.0  ...              0              0   \n",
       "2         201  0.0      0.0  ...              0              0   \n",
       "3         201  0.0      0.0  ...              0              0   \n",
       "4         201  1.0      0.0  ...              0              0   \n",
       "...       ...  ...      ...  ...            ...            ...   \n",
       "85186     220  1.0      1.0  ...              0              0   \n",
       "85187     220  1.0      1.0  ...              0              0   \n",
       "85188     220  1.0      1.0  ...              0              0   \n",
       "85189     220  1.0      1.0  ...              0              0   \n",
       "85190     220  1.0      1.0  ...              0              0   \n",
       "\n",
       "       Best Bowling Figures  Bowling Average  Bowling Economy Rate  \\\n",
       "0                         1                1                     1   \n",
       "1                         0                0                     0   \n",
       "2                         0                0                     0   \n",
       "3                         0                0                     0   \n",
       "4                         0                0                     0   \n",
       "...                     ...              ...                   ...   \n",
       "85186                     0                0                     0   \n",
       "85187                     0                0                     0   \n",
       "85188                     0                0                     0   \n",
       "85189                     0                0                     0   \n",
       "85190                     0                0                     0   \n",
       "\n",
       "       Bowling Strike Rate  4+ Innings Wickets  5+ Innings Wickets  \\\n",
       "0                        1                   1                   1   \n",
       "1                        0                   0                   0   \n",
       "2                        0                   0                   0   \n",
       "3                        0                   0                   0   \n",
       "4                        0                   0                   0   \n",
       "...                    ...                 ...                 ...   \n",
       "85186                    0                   0                   0   \n",
       "85187                    0                   0                   0   \n",
       "85188                    0                   0                   0   \n",
       "85189                    0                   0                   0   \n",
       "85190                    0                   0                   0   \n",
       "\n",
       "       Catches Taken  Stumpings Made  \n",
       "0                NaN             NaN  \n",
       "1                1.0             0.0  \n",
       "2                0.0             0.0  \n",
       "3                8.0             0.0  \n",
       "4                1.0             0.0  \n",
       "...              ...             ...  \n",
       "85186            9.0             0.0  \n",
       "85187            7.0             0.0  \n",
       "85188            4.0             0.0  \n",
       "85189           10.0             0.0  \n",
       "85190            2.0             0.0  \n",
       "\n",
       "[85191 rows x 41 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = new_ipl['venue'].unique()\n",
    "a2 = new_ipl['batting_team'].unique()\n",
    "a3 = new_ipl['bowling_team'].unique()\n",
    "a4 = new_ipl['striker'].unique()\n",
    "a5 = new_ipl['bowler'].unique()\n",
    "  \n",
    "def labelEncoding(data):\n",
    "    dataset = pd.DataFrame(new_ipl)\n",
    "    feature_dict ={}\n",
    "      \n",
    "    for feature in dataset:\n",
    "        if dataset[feature].dtype==object:\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            fs = dataset[feature].unique()\n",
    "            le.fit(fs)\n",
    "            dataset[feature] = le.transform(dataset[feature])\n",
    "            feature_dict[feature] = le\n",
    "              \n",
    "    return dataset\n",
    "  \n",
    "labelEncoding(new_ipl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47380d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M Chinnaswamy Stadium': 15,\n",
       " 'Punjab Cricket Association Stadium, Mohali': 26,\n",
       " 'Feroz Shah Kotla': 9,\n",
       " 'Eden Gardens': 8,\n",
       " 'Wankhede Stadium': 39,\n",
       " 'Sawai Mansingh Stadium': 31,\n",
       " 'Rajiv Gandhi International Stadium, Uppal': 28,\n",
       " 'MA Chidambaram Stadium, Chepauk': 18,\n",
       " 'Dr DY Patil Sports Academy': 5,\n",
       " 'Newlands': 22,\n",
       " \"St George's Park\": 35,\n",
       " 'Kingsmead': 14,\n",
       " 'SuperSport Park': 37,\n",
       " 'Buffalo Park': 3,\n",
       " 'New Wanderers Stadium': 21,\n",
       " 'De Beers Diamond Oval': 4,\n",
       " 'OUTsurance Oval': 23,\n",
       " 'Brabourne Stadium': 2,\n",
       " 'Sardar Patel Stadium, Motera': 29,\n",
       " 'Barabati Stadium': 1,\n",
       " 'Vidarbha Cricket Association Stadium, Jamtha': 38,\n",
       " 'Himachal Pradesh Cricket Association Stadium': 11,\n",
       " 'Nehru Stadium': 20,\n",
       " 'Holkar Cricket Stadium': 12,\n",
       " 'Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium': 6,\n",
       " 'Subrata Roy Sahara Stadium': 36,\n",
       " 'Shaheed Veer Narayan Singh International Stadium': 32,\n",
       " 'JSCA International Stadium Complex': 13,\n",
       " 'Sheikh Zayed Stadium': 34,\n",
       " 'Sharjah Cricket Stadium': 33,\n",
       " 'Dubai International Cricket Stadium': 7,\n",
       " 'Maharashtra Cricket Association Stadium': 19,\n",
       " 'Punjab Cricket Association IS Bindra Stadium, Mohali': 25,\n",
       " 'Saurashtra Cricket Association Stadium': 30,\n",
       " 'Green Park': 10,\n",
       " 'M.Chinnaswamy Stadium': 16,\n",
       " 'MA Chidambaram Stadium': 17,\n",
       " 'Arun Jaitley Stadium': 0,\n",
       " 'Rajiv Gandhi International Stadium': 27,\n",
       " 'Punjab Cricket Association IS Bindra Stadium': 24,\n",
       " 'Kolkata Knight Riders': 7,\n",
       " 'Chennai Super Kings': 0,\n",
       " 'Rajasthan Royals': 10,\n",
       " 'Deccan Chargers': 1,\n",
       " 'Mumbai Indians': 8,\n",
       " 'Kings XI Punjab': 5,\n",
       " 'Royal Challengers Bangalore': 13,\n",
       " 'Delhi Daredevils': 3,\n",
       " 'Kochi Tuskers Kerala': 6,\n",
       " 'Pune Warriors': 9,\n",
       " 'Sunrisers Hyderabad': 14,\n",
       " 'Rising Pune Supergiants': 12,\n",
       " 'Gujarat Lions': 4,\n",
       " 'Rising Pune Supergiant': 11,\n",
       " 'Delhi Capitals': 2,\n",
       " 'SC Ganguly': 259,\n",
       " 'BB McCullum': 30,\n",
       " 'RT Ponting': 174,\n",
       " 'PA Patel': 150,\n",
       " 'ML Hayden': 129,\n",
       " 'MEK Hussey': 123,\n",
       " 'MS Dhoni': 135,\n",
       " 'T Kohli': 213,\n",
       " 'YK Pathan': 314,\n",
       " 'SR Watson': 275,\n",
       " 'M Kaif': 113,\n",
       " 'AC Gilchrist': 9,\n",
       " 'Y Venugopal Rao': 312,\n",
       " 'VVS Laxman': 224,\n",
       " 'A Symonds': 8,\n",
       " 'L Ronchi': 108,\n",
       " 'ST Jayasuriya': 203,\n",
       " 'DJ Thornely': 56,\n",
       " 'RV Uthappa': 175,\n",
       " 'PR Shah': 156,\n",
       " 'K Goel': 131,\n",
       " 'JR Hopes': 127,\n",
       " 'KC Sangakkara': 98,\n",
       " 'DPMD Jayawardene': 59,\n",
       " 'SK Raina': 264,\n",
       " 'Shahid Afridi': 281,\n",
       " 'IK Pathan': 102,\n",
       " 'WP Saha': 228,\n",
       " 'DJ Hussey': 73,\n",
       " 'S Chanderpaul': 178,\n",
       " 'R Dravid': 160,\n",
       " 'LRPL Taylor': 112,\n",
       " 'JH Kallis': 119,\n",
       " 'V Kohli': 300,\n",
       " 'AM Rahane': 18,\n",
       " 'SM Pollock': 271,\n",
       " 'G Gambhir': 68,\n",
       " 'V Sehwag': 302,\n",
       " 'S Dhawan': 243,\n",
       " 'Shoaib Malik': 210,\n",
       " 'MK Tiwary': 128,\n",
       " 'DB Das': 49,\n",
       " 'GC Smith': 69,\n",
       " 'SA Asnodkar': 183,\n",
       " 'HH Gibbs': 74,\n",
       " 'SP Fleming': 194,\n",
       " 'S Vidyut': 182,\n",
       " 'SE Marsh': 188,\n",
       " 'Yuvraj Singh': 316,\n",
       " 'B Chipli': 28,\n",
       " 'W Jaffer': 226,\n",
       " 'S Badrinath': 177,\n",
       " 'YV Takawale': 232,\n",
       " 'CL White': 45,\n",
       " 'S Anirudha': 176,\n",
       " 'AB de Villiers': 7,\n",
       " 'A Chopra': 0,\n",
       " 'BJ Hodge': 51,\n",
       " 'Salman Butt': 207,\n",
       " 'J Arunkumar': 81,\n",
       " 'Misbah-ul-Haq': 139,\n",
       " 'Mohammad Hafeez': 186,\n",
       " 'SR Tendulkar': 199,\n",
       " 'SP Goswami': 195,\n",
       " 'LA Pomersbach': 109,\n",
       " 'SB Styris': 257,\n",
       " 'MV Boucher': 137,\n",
       " 'JD Ryder': 113,\n",
       " 'KP Pietersen': 147,\n",
       " 'RS Bopara': 236,\n",
       " 'CH Gayle': 56,\n",
       " 'TM Dilshan': 296,\n",
       " 'PC Valthaty': 152,\n",
       " 'RJ Quiney': 169,\n",
       " 'DR Smith': 82,\n",
       " 'KD Karthik': 99,\n",
       " 'AA Bilakhia': 4,\n",
       " 'RG Sharma': 229,\n",
       " 'Harbhajan Singh': 98,\n",
       " 'AM Nayar': 27,\n",
       " 'R Bishnoi': 159,\n",
       " 'M Vijay': 168,\n",
       " 'JP Duminy': 125,\n",
       " 'DJ Bravo': 70,\n",
       " 'NV Ojha': 146,\n",
       " 'MN van Wyk': 132,\n",
       " 'TL Suman': 295,\n",
       " 'Yashpal Singh': 233,\n",
       " 'S Sohal': 181,\n",
       " 'SM Katich': 191,\n",
       " 'AN Ghosh': 19,\n",
       " 'DA Warner': 48,\n",
       " 'GJ Bailey': 71,\n",
       " 'M Manhas': 115,\n",
       " 'Niraj Patel': 147,\n",
       " 'J Botha': 106,\n",
       " 'MK Pandey': 127,\n",
       " 'RE van der Merwe': 227,\n",
       " 'Mohammad Ashraful': 140,\n",
       " 'CA Pujara': 41,\n",
       " 'OA Shah': 148,\n",
       " 'AD Mathews': 20,\n",
       " 'MS Bisla': 134,\n",
       " 'AP Tare': 21,\n",
       " 'SS Tiwary': 202,\n",
       " 'AT Rayudu': 24,\n",
       " 'EJG Morgan': 64,\n",
       " 'AA Jhunjhunwala': 12,\n",
       " 'MJ Lumb': 126,\n",
       " 'DR Martyn': 60,\n",
       " 'FY Fazal': 67,\n",
       " 'MD Mishra': 121,\n",
       " 'Mandeep Singh': 138,\n",
       " 'PD Collingwood': 153,\n",
       " 'KM Jadhav': 104,\n",
       " 'C Madan': 36,\n",
       " 'AG Paunikar': 14,\n",
       " 'R McLaren': 218,\n",
       " 'Anirudh Singh': 25,\n",
       " 'IR Jaggi': 79,\n",
       " 'Sunny Singh': 212,\n",
       " 'UBT Chand': 218,\n",
       " 'AJ Finch': 24,\n",
       " 'MA Agarwal': 118,\n",
       " 'RA Jadeja': 226,\n",
       " 'AL Menaria': 26,\n",
       " 'DJ Jacobs': 55,\n",
       " 'AS Raut': 23,\n",
       " 'TD Paine': 214,\n",
       " 'BJ Haddin': 33,\n",
       " 'R Sathish': 162,\n",
       " 'MS Wade': 136,\n",
       " 'Y Nagar': 311,\n",
       " 'AC Blizzard': 8,\n",
       " 'M Klinger': 114,\n",
       " 'DB Ravi Teja': 50,\n",
       " 'CJ Ferguson': 44,\n",
       " 'CA Ingram': 39,\n",
       " 'RN ten Doeschate': 170,\n",
       " 'F du Plessis': 66,\n",
       " 'LR Shukla': 160,\n",
       " 'R Bhatia': 216,\n",
       " 'WD Parnell': 308,\n",
       " 'AB McDonald': 16,\n",
       " 'MN Samuels': 181,\n",
       " 'DT Christian': 84,\n",
       " 'RE Levi': 166,\n",
       " 'N Saini': 143,\n",
       " 'JEC Franklin': 118,\n",
       " 'DJ Harris': 71,\n",
       " 'MJ Clarke': 175,\n",
       " 'AP Majumdar': 20,\n",
       " 'STR Binny': 278,\n",
       " 'SD Chitnis': 261,\n",
       " 'Azhar Mahmood': 38,\n",
       " 'PA Reddy': 151,\n",
       " 'MC Juneja': 120,\n",
       " 'MDKJ Perera': 122,\n",
       " 'KK Nair': 102,\n",
       " 'M Vohra': 117,\n",
       " 'Gurkeerat Singh': 94,\n",
       " 'Q de Kock': 157,\n",
       " 'GH Vihari': 90,\n",
       " 'BB Samantray': 31,\n",
       " 'KV Sharma': 149,\n",
       " 'A Mishra': 4,\n",
       " 'NLTC Perera': 196,\n",
       " 'DJG Sammy': 76,\n",
       " 'A Mukund': 2,\n",
       " 'JP Faulkner': 126,\n",
       " 'SV Samson': 205,\n",
       " 'CM Gautam': 46,\n",
       " 'MC Henriques': 171,\n",
       " 'GJ Maxwell': 91,\n",
       " 'CA Lynn': 40,\n",
       " 'CJ Anderson': 58,\n",
       " 'S Rana': 180,\n",
       " 'JA Morkel': 111,\n",
       " 'KL Rahul': 103,\n",
       " 'BR Dunk': 35,\n",
       " 'DA Miller': 47,\n",
       " 'LMP Simmons': 110,\n",
       " 'VH Zol': 223,\n",
       " 'Ankit Sharma': 35,\n",
       " 'KK Cooper': 143,\n",
       " 'RR Rossouw': 172,\n",
       " 'SS Iyer': 201,\n",
       " 'SPD Smith': 198,\n",
       " 'AD Russell': 21,\n",
       " 'AR Patel': 31,\n",
       " 'KA Pollard': 137,\n",
       " 'HH Pandya': 96,\n",
       " 'JC Buttler': 85,\n",
       " 'P Negi': 202,\n",
       " 'DJ Hooda': 72,\n",
       " 'MJ Guptill': 125,\n",
       " 'SW Billings': 206,\n",
       " 'KS Williamson': 148,\n",
       " 'MP Stoinis': 182,\n",
       " 'RR Pant': 171,\n",
       " 'UT Khawaja': 219,\n",
       " 'HM Amla': 76,\n",
       " 'SA Yadav': 254,\n",
       " 'Shakib Al Hasan': 282,\n",
       " 'N Rana': 192,\n",
       " 'KH Pandya': 140,\n",
       " 'PP Chawla': 210,\n",
       " 'C Munro': 37,\n",
       " 'ER Dwivedi': 65,\n",
       " 'JJ Roy': 89,\n",
       " 'Vishnu Vinod': 225,\n",
       " 'RA Tripathi': 165,\n",
       " 'BA Stokes': 46,\n",
       " 'SP Narine': 274,\n",
       " 'TM Head': 217,\n",
       " 'Ishan Kishan': 80,\n",
       " 'SP Jackson': 196,\n",
       " 'R Tewatia': 224,\n",
       " 'C de Grandhomme': 55,\n",
       " 'MM Ali': 178,\n",
       " 'JM Bairstow': 91,\n",
       " 'PP Shaw': 155,\n",
       " 'NS Naik': 145,\n",
       " 'SM Curran': 269,\n",
       " 'SN Khan': 193,\n",
       " 'V Shankar': 222,\n",
       " 'Shubman Gill': 211,\n",
       " 'JL Denly': 90,\n",
       " 'E Lewis': 63,\n",
       " 'DJM Short': 58,\n",
       " 'AD Hales': 10,\n",
       " 'K Gowtham': 132,\n",
       " 'JC Archer': 112,\n",
       " 'BCJ Cutting': 49,\n",
       " 'AD Nath': 12,\n",
       " 'P Kumar': 201,\n",
       " 'Z Khan': 317,\n",
       " 'AA Noffke': 13,\n",
       " 'B Lee': 43,\n",
       " 'S Sreesanth': 251,\n",
       " 'GD McGrath': 89,\n",
       " 'B Geeves': 40,\n",
       " 'MF Maharoof': 172,\n",
       " 'AB Dinda': 15,\n",
       " 'I Sharma': 100,\n",
       " 'AB Agarkar': 14,\n",
       " 'M Kartik': 162,\n",
       " 'R Vinay Kumar': 225,\n",
       " 'MM Patel': 179,\n",
       " 'SK Trivedi': 265,\n",
       " 'SK Warne': 266,\n",
       " 'Mohammad Asif': 185,\n",
       " 'A Nehra': 6,\n",
       " 'DS Kulkarni': 83,\n",
       " 'Pankaj Singh': 213,\n",
       " 'JDP Oram': 115,\n",
       " 'MS Gony': 184,\n",
       " 'P Amarnath': 199,\n",
       " 'M Muralitharan': 165,\n",
       " 'Sohail Tanvir': 286,\n",
       " 'RP Singh': 232,\n",
       " 'DNT Zoysa': 79,\n",
       " 'SB Bangar': 255,\n",
       " 'VRV Singh': 304,\n",
       " 'DW Steyn': 85,\n",
       " 'CRD Fernando': 64,\n",
       " 'Umar Gul': 299,\n",
       " 'VY Mahesh': 307,\n",
       " 'PJ Sangwan': 208,\n",
       " 'DP Vijaykumar': 81,\n",
       " 'Gagandeep Singh': 93,\n",
       " 'A Kumble': 3,\n",
       " 'WPUJC Vaas': 309,\n",
       " 'AD Mascarenhas': 19,\n",
       " 'PM Sarvesh Kumar': 209,\n",
       " 'RR Powar': 234,\n",
       " 'M Ntini': 166,\n",
       " 'VS Yeligati': 306,\n",
       " 'BAW Mendis': 47,\n",
       " 'Kamran Khan': 151,\n",
       " 'T Thushara': 291,\n",
       " 'A Flintoff': 2,\n",
       " 'DP Nannes': 80,\n",
       " 'AM Salvi': 28,\n",
       " 'DL Vettori': 78,\n",
       " 'FH Edwards': 86,\n",
       " 'Harmeet Singh': 99,\n",
       " 'PP Ojha': 211,\n",
       " 'L Balaji': 155,\n",
       " 'Joginder Sharma': 130,\n",
       " 'Anureet Singh': 36,\n",
       " 'RR Bose': 233,\n",
       " 'YA Abdulla': 313,\n",
       " 'SL Malinga': 267,\n",
       " 'VS Malik': 305,\n",
       " 'SM Harwood': 270,\n",
       " 'D du Preez': 67,\n",
       " 'RJ Harris': 230,\n",
       " 'Shoaib Ahmed': 285,\n",
       " 'A Singh': 7,\n",
       " 'M Morkel': 164,\n",
       " 'LA Carseldine': 157,\n",
       " 'S Tyagi': 252,\n",
       " 'A Mithun': 5,\n",
       " 'RR Raje': 235,\n",
       " 'B Akhil': 39,\n",
       " 'CK Langeveldt': 61,\n",
       " 'Jaskaran Singh': 129,\n",
       " 'SW Tait': 279,\n",
       " 'A Uniyal': 9,\n",
       " 'R Ashwin': 215,\n",
       " 'SE Bond': 262,\n",
       " 'S Ladda': 247,\n",
       " 'JM Kemp': 122,\n",
       " 'SJ Srivastava': 263,\n",
       " 'Bipul Sharma': 54,\n",
       " 'J Theron': 109,\n",
       " 'S Narwal': 250,\n",
       " 'KAJ Roach': 138,\n",
       " 'SB Jakati': 256,\n",
       " 'AC Voges': 18,\n",
       " 'SB Wagh': 258,\n",
       " 'AN Ahmed': 29,\n",
       " 'AP Dole': 30,\n",
       " 'MR Marsh': 183,\n",
       " 'L Ablish': 154,\n",
       " 'DE Bollinger': 69,\n",
       " 'UT Yadav': 298,\n",
       " 'JD Unadkat': 114,\n",
       " 'Iqbal Abdulla': 105,\n",
       " 'AC Thomas': 17,\n",
       " 'AG Murtaza': 23,\n",
       " 'JJ van der Wath': 121,\n",
       " 'S Aravind': 241,\n",
       " 'RV Gomez': 237,\n",
       " 'R Ninan': 219,\n",
       " 'J Syed Mohammad': 108,\n",
       " 'NL McCullum': 195,\n",
       " 'JE Taylor': 117,\n",
       " 'R Sharma': 222,\n",
       " 'KMDN Kulasekara': 145,\n",
       " 'TG Southee': 293,\n",
       " 'BA Bhatt': 45,\n",
       " 'P Parameswaran': 203,\n",
       " 'S Nadeem': 249,\n",
       " 'B Kumar': 41,\n",
       " 'VR Aaron': 303,\n",
       " 'AA Chavan': 11,\n",
       " 'SS Mundhe': 277,\n",
       " 'RW Price': 238,\n",
       " 'DAJ Bracewell': 68,\n",
       " 'HV Patel': 97,\n",
       " 'GB Hogg': 87,\n",
       " 'P Awana': 200,\n",
       " 'A Chandila': 0,\n",
       " 'RJ Peterson': 231,\n",
       " 'CJ McKay': 60,\n",
       " 'R Shukla': 223,\n",
       " 'KP Appanna': 146,\n",
       " 'V Pratap Singh': 301,\n",
       " 'BW Hilfenhaus': 52,\n",
       " 'K Upadhyay': 136,\n",
       " 'Sunny Gupta': 287,\n",
       " 'MG Johnson': 173,\n",
       " 'JJ Bumrah': 120,\n",
       " 'AS Rajpoot': 33,\n",
       " 'Mohammed Shami': 188,\n",
       " 'CH Morris': 57,\n",
       " 'Anand Rajan': 34,\n",
       " 'MM Sharma': 180,\n",
       " 'SMSM Senanayake': 272,\n",
       " 'R Rampaul': 221,\n",
       " 'R Dhawan': 217,\n",
       " 'JO Holder': 123,\n",
       " 'IC Pandey': 101,\n",
       " 'KW Richardson': 150,\n",
       " 'MG Neser': 174,\n",
       " 'PV Tambe': 212,\n",
       " 'Parvez Rasool': 214,\n",
       " 'S Kaul': 245,\n",
       " 'Sandeep Sharma': 280,\n",
       " 'NM Coulter-Nile': 197,\n",
       " 'MA Starc': 170,\n",
       " 'JDS Neesham': 116,\n",
       " 'YS Chahal': 315,\n",
       " 'S Badree': 242,\n",
       " 'Shivam Sharma': 284,\n",
       " 'Imran Tahir': 104,\n",
       " 'BE Hendricks': 50,\n",
       " 'PJ Cummins': 207,\n",
       " 'K Santokie': 135,\n",
       " 'S Gopal': 244,\n",
       " 'Karanveer Singh': 152,\n",
       " 'D Wiese': 66,\n",
       " 'MJ McClenaghan': 176,\n",
       " 'DJ Muthuswami': 74,\n",
       " 'SA Abbott': 253,\n",
       " 'TA Boult': 292,\n",
       " 'P Suyal': 206,\n",
       " 'RG More': 228,\n",
       " 'GS Sandhu': 92,\n",
       " 'J Suchith': 107,\n",
       " 'M de Lange': 169,\n",
       " 'J Yadav': 110,\n",
       " 'JW Hastings': 128,\n",
       " 'Mustafizur Rahman': 191,\n",
       " 'CR Brathwaite': 62,\n",
       " 'KJ Abbott': 141,\n",
       " 'P Sahu': 205,\n",
       " 'BB Sran': 48,\n",
       " 'T Shamsi': 290,\n",
       " 'Swapnil Singh': 288,\n",
       " 'SM Boland': 268,\n",
       " 'CJ Jordan': 59,\n",
       " 'S Kaushik': 246,\n",
       " 'DL Chahar': 77,\n",
       " 'KC Cariappa': 139,\n",
       " 'TS Mills': 297,\n",
       " 'A Choudhary': 1,\n",
       " 'CR Woakes': 63,\n",
       " 'Kuldeep Yadav': 153,\n",
       " 'T Natarajan': 289,\n",
       " 'Rashid Khan': 239,\n",
       " 'Basil Thampi': 53,\n",
       " 'AJ Tye': 25,\n",
       " 'AF Milne': 22,\n",
       " 'K Rabada': 134,\n",
       " 'Washington Sundar': 310,\n",
       " 'SN Thakur': 273,\n",
       " 'SS Agarwal': 276,\n",
       " 'NB Singh': 194,\n",
       " 'Mohammad Nabi': 187,\n",
       " 'Mohammed Siraj': 189,\n",
       " 'A Zampa': 10,\n",
       " 'LH Ferguson': 159,\n",
       " 'M Prasidh Krishna': 167,\n",
       " 'Rasikh Salam': 240,\n",
       " 'CV Varun': 65,\n",
       " 'GC Viljoen': 88,\n",
       " 'NA Saini': 193,\n",
       " 'M Ashwin': 161,\n",
       " 'S Lamichhane': 248,\n",
       " 'P Ray Barman': 204,\n",
       " 'Avesh Khan': 37,\n",
       " 'Mujeeb Ur Rahman': 190,\n",
       " 'SC Kuggeleijn': 260,\n",
       " 'JP Behrendorff': 124,\n",
       " 'AS Joseph': 32,\n",
       " 'MJ Santner': 177,\n",
       " 'KMA Paul': 144,\n",
       " 'KK Ahmed': 142,\n",
       " 'IS Sodhi': 103,\n",
       " 'B Stanlake': 44,\n",
       " 'K Khejroliya': 133,\n",
       " 'Shivam Mavi': 283,\n",
       " 'B Laughlin': 42,\n",
       " 'LE Plunkett': 158,\n",
       " 'M Markande': 163,\n",
       " 'DJ Willey': 75,\n",
       " 'L Ngidi': 156,\n",
       " 'TK Curran': 294,\n",
       " 'HF Gurney': 95,\n",
       " 'R Parag': 220,\n",
       " 'O Thomas': 198}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_dataset = new_ipl[['venue','innings', 'batting_team', \n",
    "                      'bowling_team', 'striker', 'non_striker',\n",
    "                      'bowler']]\n",
    "  \n",
    "b1 = ip_dataset['venue'].unique()\n",
    "b2 = ip_dataset['batting_team'].unique()\n",
    "b3 = ip_dataset['bowling_team'].unique()\n",
    "b4 = ip_dataset['striker'].unique()\n",
    "b5 = ip_dataset['bowler'].unique()\n",
    "new_ipl.fillna(0,inplace=True)\n",
    "  \n",
    "features={}\n",
    "  \n",
    "for i in range(len(a1)):\n",
    "    features[a1[i]]=b1[i]\n",
    "for i in range(len(a2)):\n",
    "    features[a2[i]]=b2[i]\n",
    "for i in range(len(a3)):\n",
    "    features[a3[i]]=b3[i]\n",
    "for i in range(len(a4)):\n",
    "    features[a4[i]]=b4[i]\n",
    "for i in range(len(a5)):\n",
    "    features[a5[i]]=b5[i]\n",
    "      \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad30520",
   "metadata": {},
   "source": [
    "Step 4: Feature Engineering and Selection\n",
    "\n",
    "Our dataset contains multiple columns, but we can’t take these many inputs from users thus we have taken the selected amount of features as input and divided them into X and y. We will then divide our data into train sets and test set before using a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba80fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_ipl[['venue', 'innings','batting_team',\n",
    "             'bowling_team', 'striker','bowler']].values\n",
    "y = new_ipl['y'].values\n",
    "  \n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751ae84",
   "metadata": {},
   "source": [
    "Comparing these large numerical values by our model will be difficult so it is always a better choice to scale your data before processing it. Here we are using MinMaxScaler from sklearn.preprocessing which is recommended when dealing with deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9127c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "  \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f7f24",
   "metadata": {},
   "source": [
    "Note: We cannot fit X_test as it is the data which is to be predicted. \n",
    "\n",
    "Step 5: Building, Training & Testing the Model\n",
    "\n",
    "Here comes the most exciting part of our project, Building our model! Firstly, we will import Sequential from tensorflow.keras.models Also, we will import Dense & Dropout from tensorflow.keras.layers as we will be using multiple layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828fa192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea58c45",
   "metadata": {},
   "source": [
    "EarlyStopping is used to avoid overfitting. What early stopping basically does is, it stops calculating the losses when ‘val_loss’ increases than ‘loss’. Val_loss curve should always be below val curve. When it is found that the difference between ‘val_loss’ and ‘loss’ is becomes constant, it stops training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c5ac4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "  \n",
    "model.add(Dense(43, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "  \n",
    "model.add(Dense(22, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "  \n",
    "model.add(Dense(11, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "  \n",
    "model.add(Dense(1))\n",
    "  \n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322cbe8",
   "metadata": {},
   "source": [
    "Here, we have created 2 hidden layers and reduced the number of neurons as we want the final output to be 1. Then while compiling our model we used adam optimizer and loss as mean squared error.  Now, let’s start training our model with epochs=400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "622e8add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1784/1784 [==============================] - 12s 5ms/step - loss: 974.5809 - val_loss: 299.7319\n",
      "Epoch 2/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 680.9727 - val_loss: 273.6363\n",
      "Epoch 3/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 614.5026 - val_loss: 226.7275\n",
      "Epoch 4/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 558.8760 - val_loss: 233.7936\n",
      "Epoch 5/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 519.7264 - val_loss: 208.3313\n",
      "Epoch 6/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 491.7924 - val_loss: 216.7101\n",
      "Epoch 7/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 450.8994 - val_loss: 203.9463\n",
      "Epoch 8/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 402.6416 - val_loss: 185.5817\n",
      "Epoch 9/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 371.3091 - val_loss: 191.0267\n",
      "Epoch 10/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 349.6723 - val_loss: 176.3151\n",
      "Epoch 11/400\n",
      "1784/1784 [==============================] - 26s 15ms/step - loss: 335.8818 - val_loss: 172.8381\n",
      "Epoch 12/400\n",
      "1784/1784 [==============================] - 27s 15ms/step - loss: 318.9810 - val_loss: 170.6364\n",
      "Epoch 13/400\n",
      "1784/1784 [==============================] - 14s 8ms/step - loss: 303.2537 - val_loss: 169.7258\n",
      "Epoch 14/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 290.1281 - val_loss: 170.6850\n",
      "Epoch 15/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 274.7481 - val_loss: 163.4265\n",
      "Epoch 16/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 266.3980 - val_loss: 165.8206\n",
      "Epoch 17/400\n",
      "1784/1784 [==============================] - 14s 8ms/step - loss: 251.9863 - val_loss: 161.1419\n",
      "Epoch 18/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 242.2330 - val_loss: 159.5964\n",
      "Epoch 19/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 230.3832 - val_loss: 158.1573\n",
      "Epoch 20/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 222.7101 - val_loss: 157.4273\n",
      "Epoch 21/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 214.9171 - val_loss: 154.1772\n",
      "Epoch 22/400\n",
      "1784/1784 [==============================] - 14s 8ms/step - loss: 207.2304 - val_loss: 155.8249\n",
      "Epoch 23/400\n",
      "1784/1784 [==============================] - 14s 8ms/step - loss: 196.3119 - val_loss: 153.0216\n",
      "Epoch 24/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 191.5375 - val_loss: 151.9690\n",
      "Epoch 25/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 185.8128 - val_loss: 150.6822\n",
      "Epoch 26/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 180.3275 - val_loss: 149.7669\n",
      "Epoch 27/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 174.6722 - val_loss: 148.3226\n",
      "Epoch 28/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 170.4519 - val_loss: 147.3082\n",
      "Epoch 29/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 167.6788 - val_loss: 147.2138\n",
      "Epoch 30/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 163.5445 - val_loss: 146.1311\n",
      "Epoch 31/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 160.5841 - val_loss: 146.5470\n",
      "Epoch 32/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 158.0108 - val_loss: 146.0674\n",
      "Epoch 33/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 156.0308 - val_loss: 146.0264\n",
      "Epoch 34/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 153.6719 - val_loss: 145.8994\n",
      "Epoch 35/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 152.4494 - val_loss: 145.2699\n",
      "Epoch 36/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 151.4338 - val_loss: 145.3612\n",
      "Epoch 37/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 150.0165 - val_loss: 144.5752\n",
      "Epoch 38/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 149.2626 - val_loss: 143.8967\n",
      "Epoch 39/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 148.4724 - val_loss: 144.2076\n",
      "Epoch 40/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 147.8296 - val_loss: 143.5385\n",
      "Epoch 41/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 147.5254 - val_loss: 144.3129\n",
      "Epoch 42/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 147.1125 - val_loss: 143.9518\n",
      "Epoch 43/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 146.6911 - val_loss: 144.4942\n",
      "Epoch 44/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 146.5318 - val_loss: 143.9577\n",
      "Epoch 45/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 146.4194 - val_loss: 143.3053\n",
      "Epoch 46/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 146.0165 - val_loss: 143.8730\n",
      "Epoch 47/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 146.0482 - val_loss: 143.6944\n",
      "Epoch 48/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 145.9136 - val_loss: 143.9212\n",
      "Epoch 49/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 145.8432 - val_loss: 143.4273\n",
      "Epoch 50/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 145.8279 - val_loss: 143.7740\n",
      "Epoch 51/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 145.8554 - val_loss: 143.5371\n",
      "Epoch 52/400\n",
      "1784/1784 [==============================] - 8s 4ms/step - loss: 145.7978 - val_loss: 143.4532\n",
      "Epoch 53/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 145.3760 - val_loss: 142.9923\n",
      "Epoch 54/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 145.3080 - val_loss: 142.8337\n",
      "Epoch 55/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 145.3660 - val_loss: 142.9218\n",
      "Epoch 56/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 145.0824 - val_loss: 142.9004\n",
      "Epoch 57/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.9973 - val_loss: 142.2736\n",
      "Epoch 58/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.9322 - val_loss: 142.7643\n",
      "Epoch 59/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 145.1480 - val_loss: 142.6356\n",
      "Epoch 60/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.7603 - val_loss: 142.7872\n",
      "Epoch 61/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 145.0076 - val_loss: 142.6094\n",
      "Epoch 62/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.8976 - val_loss: 142.3773\n",
      "Epoch 63/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 144.5907 - val_loss: 142.4475\n",
      "Epoch 64/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.9023 - val_loss: 141.8305\n",
      "Epoch 65/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.6214 - val_loss: 142.0442\n",
      "Epoch 66/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 144.5304 - val_loss: 142.3380\n",
      "Epoch 67/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.5348 - val_loss: 141.3695\n",
      "Epoch 68/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 144.4135 - val_loss: 141.7628\n",
      "Epoch 69/400\n",
      "1784/1784 [==============================] - 8s 4ms/step - loss: 144.6345 - val_loss: 141.8649\n",
      "Epoch 70/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 144.5967 - val_loss: 141.5409\n",
      "Epoch 71/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 144.4997 - val_loss: 141.4661\n",
      "Epoch 72/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.3873 - val_loss: 141.5645\n",
      "Epoch 73/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.5725 - val_loss: 141.2187\n",
      "Epoch 74/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 144.1903 - val_loss: 141.1334\n",
      "Epoch 75/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.1256 - val_loss: 141.1747\n",
      "Epoch 76/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784/1784 [==============================] - 11s 6ms/step - loss: 144.2089 - val_loss: 140.7892\n",
      "Epoch 77/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 144.1145 - val_loss: 141.0306\n",
      "Epoch 78/400\n",
      "1784/1784 [==============================] - 8s 4ms/step - loss: 144.2416 - val_loss: 141.0420\n",
      "Epoch 79/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 144.1839 - val_loss: 141.7402\n",
      "Epoch 80/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 144.4023 - val_loss: 141.2004\n",
      "Epoch 81/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 144.0712 - val_loss: 140.3567\n",
      "Epoch 82/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 143.9855 - val_loss: 141.5555\n",
      "Epoch 83/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 144.2154 - val_loss: 140.7216\n",
      "Epoch 84/400\n",
      "1784/1784 [==============================] - 13s 8ms/step - loss: 144.1738 - val_loss: 141.0098\n",
      "Epoch 85/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 143.9905 - val_loss: 140.1730\n",
      "Epoch 86/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 144.2057 - val_loss: 140.7783\n",
      "Epoch 87/400\n",
      "1784/1784 [==============================] - 15s 8ms/step - loss: 143.9767 - val_loss: 140.9508\n",
      "Epoch 88/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 144.1128 - val_loss: 140.7440\n",
      "Epoch 89/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 144.0898 - val_loss: 140.0121\n",
      "Epoch 90/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 143.9986 - val_loss: 140.4927\n",
      "Epoch 91/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 143.6971 - val_loss: 139.9583\n",
      "Epoch 92/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 143.7294 - val_loss: 140.0169\n",
      "Epoch 93/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.6126 - val_loss: 139.9429\n",
      "Epoch 94/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.8829 - val_loss: 139.8089\n",
      "Epoch 95/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 143.8716 - val_loss: 140.0362\n",
      "Epoch 96/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 143.9599 - val_loss: 139.8212\n",
      "Epoch 97/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 143.7157 - val_loss: 139.5828\n",
      "Epoch 98/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 143.8438 - val_loss: 140.4720\n",
      "Epoch 99/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 144.1039 - val_loss: 140.6274\n",
      "Epoch 100/400\n",
      "1784/1784 [==============================] - 13s 8ms/step - loss: 143.6373 - val_loss: 139.8586\n",
      "Epoch 101/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 143.6164 - val_loss: 139.2902\n",
      "Epoch 102/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 143.4191 - val_loss: 139.1275\n",
      "Epoch 103/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.2511 - val_loss: 139.0438\n",
      "Epoch 104/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.9761 - val_loss: 139.1891\n",
      "Epoch 105/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.2441 - val_loss: 138.9615\n",
      "Epoch 106/400\n",
      "1784/1784 [==============================] - 14s 8ms/step - loss: 142.8918 - val_loss: 138.6994\n",
      "Epoch 107/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 143.1576 - val_loss: 138.5134\n",
      "Epoch 108/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.1322 - val_loss: 138.6391\n",
      "Epoch 109/400\n",
      "1784/1784 [==============================] - 14s 8ms/step - loss: 143.2880 - val_loss: 138.9837\n",
      "Epoch 110/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.0857 - val_loss: 138.5214\n",
      "Epoch 111/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 142.8477 - val_loss: 138.4377\n",
      "Epoch 112/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 143.1628 - val_loss: 139.5719\n",
      "Epoch 113/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.8788 - val_loss: 139.1799\n",
      "Epoch 114/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.7527 - val_loss: 138.6774\n",
      "Epoch 115/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.0352 - val_loss: 139.5314\n",
      "Epoch 116/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 143.3399 - val_loss: 139.1746\n",
      "Epoch 117/400\n",
      "1784/1784 [==============================] - 14s 8ms/step - loss: 142.7712 - val_loss: 138.7184\n",
      "Epoch 118/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 142.8919 - val_loss: 138.3916\n",
      "Epoch 119/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 142.7313 - val_loss: 138.8728\n",
      "Epoch 120/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.8217 - val_loss: 138.3992\n",
      "Epoch 121/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 142.9494 - val_loss: 138.7218\n",
      "Epoch 122/400\n",
      "1784/1784 [==============================] - 16s 9ms/step - loss: 143.0042 - val_loss: 138.5826\n",
      "Epoch 123/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.3772 - val_loss: 138.1388\n",
      "Epoch 124/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 142.6627 - val_loss: 138.8792\n",
      "Epoch 125/400\n",
      "1784/1784 [==============================] - 15s 8ms/step - loss: 142.6870 - val_loss: 138.4902\n",
      "Epoch 126/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.9688 - val_loss: 138.3581\n",
      "Epoch 127/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 142.8654 - val_loss: 138.7081\n",
      "Epoch 128/400\n",
      "1784/1784 [==============================] - 15s 9ms/step - loss: 142.8963 - val_loss: 138.5973\n",
      "Epoch 129/400\n",
      "1784/1784 [==============================] - 13s 8ms/step - loss: 142.6570 - val_loss: 137.9672\n",
      "Epoch 130/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 142.7694 - val_loss: 138.6155\n",
      "Epoch 131/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.4531 - val_loss: 137.5398\n",
      "Epoch 132/400\n",
      "1784/1784 [==============================] - 13s 7ms/step - loss: 142.6409 - val_loss: 137.9782\n",
      "Epoch 133/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 143.1389 - val_loss: 138.6464\n",
      "Epoch 134/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 142.3934 - val_loss: 137.8649\n",
      "Epoch 135/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.6497 - val_loss: 138.0559\n",
      "Epoch 136/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.6448 - val_loss: 138.5190\n",
      "Epoch 137/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.4855 - val_loss: 137.6414\n",
      "Epoch 138/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.4547 - val_loss: 138.7610\n",
      "Epoch 139/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.6411 - val_loss: 138.6510\n",
      "Epoch 140/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.6036 - val_loss: 137.6228\n",
      "Epoch 141/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.5768 - val_loss: 137.6501\n",
      "Epoch 142/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 142.2528 - val_loss: 138.8612\n",
      "Epoch 143/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.3513 - val_loss: 137.7921\n",
      "Epoch 144/400\n",
      "1784/1784 [==============================] - 13s 8ms/step - loss: 142.3722 - val_loss: 137.8839\n",
      "Epoch 145/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.4130 - val_loss: 137.5060\n",
      "Epoch 146/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.2894 - val_loss: 138.2099\n",
      "Epoch 147/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.2266 - val_loss: 137.9710\n",
      "Epoch 148/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.5831 - val_loss: 137.8050\n",
      "Epoch 149/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.4932 - val_loss: 138.3301\n",
      "Epoch 150/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.2876 - val_loss: 138.3413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.4400 - val_loss: 138.4625\n",
      "Epoch 152/400\n",
      "1784/1784 [==============================] - 8s 4ms/step - loss: 141.8971 - val_loss: 137.6559\n",
      "Epoch 153/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 141.8602 - val_loss: 137.4227\n",
      "Epoch 154/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 142.1317 - val_loss: 137.6000\n",
      "Epoch 155/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.2525 - val_loss: 138.5056\n",
      "Epoch 156/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 142.1892 - val_loss: 137.3258\n",
      "Epoch 157/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 141.8702 - val_loss: 136.8313\n",
      "Epoch 158/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.0097 - val_loss: 137.0553\n",
      "Epoch 159/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 142.3392 - val_loss: 138.6422\n",
      "Epoch 160/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.6266 - val_loss: 137.7680\n",
      "Epoch 161/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.1798 - val_loss: 137.7289\n",
      "Epoch 162/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.2603 - val_loss: 136.9286\n",
      "Epoch 163/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.1016 - val_loss: 137.6412\n",
      "Epoch 164/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.2700 - val_loss: 137.8116\n",
      "Epoch 165/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.9023 - val_loss: 138.8501\n",
      "Epoch 166/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 142.7702 - val_loss: 139.4027\n",
      "Epoch 167/400\n",
      "1784/1784 [==============================] - 8s 5ms/step - loss: 142.4321 - val_loss: 137.2914\n",
      "Epoch 168/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.4406 - val_loss: 138.8376\n",
      "Epoch 169/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.8164 - val_loss: 138.2336\n",
      "Epoch 170/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3805 - val_loss: 137.8876\n",
      "Epoch 171/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1797 - val_loss: 138.4110\n",
      "Epoch 172/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.9908 - val_loss: 138.2204\n",
      "Epoch 173/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3259 - val_loss: 137.4256\n",
      "Epoch 174/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2056 - val_loss: 137.9888\n",
      "Epoch 175/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3359 - val_loss: 138.7488\n",
      "Epoch 176/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1173 - val_loss: 138.0013\n",
      "Epoch 177/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2897 - val_loss: 137.9654\n",
      "Epoch 178/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5437 - val_loss: 138.4542\n",
      "Epoch 179/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3990 - val_loss: 137.5742\n",
      "Epoch 180/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3233 - val_loss: 137.1657\n",
      "Epoch 181/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2842 - val_loss: 137.1438\n",
      "Epoch 182/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0128 - val_loss: 137.2133\n",
      "Epoch 183/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4910 - val_loss: 137.5632\n",
      "Epoch 184/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3873 - val_loss: 137.1458\n",
      "Epoch 185/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5219 - val_loss: 138.1678\n",
      "Epoch 186/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3426 - val_loss: 137.8769\n",
      "Epoch 187/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2463 - val_loss: 137.8359\n",
      "Epoch 188/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3549 - val_loss: 137.6460\n",
      "Epoch 189/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4440 - val_loss: 138.7506\n",
      "Epoch 190/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0905 - val_loss: 137.0985\n",
      "Epoch 191/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3100 - val_loss: 137.7811\n",
      "Epoch 192/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0031 - val_loss: 137.3574\n",
      "Epoch 193/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4784 - val_loss: 136.9169\n",
      "Epoch 194/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0112 - val_loss: 137.9350\n",
      "Epoch 195/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.8209 - val_loss: 137.3046\n",
      "Epoch 196/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.7319 - val_loss: 138.1828\n",
      "Epoch 197/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2817 - val_loss: 137.7925\n",
      "Epoch 198/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.6965 - val_loss: 137.7487\n",
      "Epoch 199/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1376 - val_loss: 137.5855\n",
      "Epoch 200/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3910 - val_loss: 138.3785\n",
      "Epoch 201/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4197 - val_loss: 138.4767\n",
      "Epoch 202/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3901 - val_loss: 137.9943\n",
      "Epoch 203/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2921 - val_loss: 138.3355\n",
      "Epoch 204/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.9488 - val_loss: 137.9277\n",
      "Epoch 205/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3255 - val_loss: 137.0031\n",
      "Epoch 206/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3235 - val_loss: 137.6496\n",
      "Epoch 207/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1353 - val_loss: 138.4440\n",
      "Epoch 208/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3383 - val_loss: 138.7922\n",
      "Epoch 209/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.9006 - val_loss: 136.9997\n",
      "Epoch 210/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2032 - val_loss: 137.2793\n",
      "Epoch 211/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2182 - val_loss: 138.0520\n",
      "Epoch 212/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0164 - val_loss: 137.3737\n",
      "Epoch 213/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3121 - val_loss: 137.5765\n",
      "Epoch 214/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.9548 - val_loss: 138.2849\n",
      "Epoch 215/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.6402 - val_loss: 138.6164\n",
      "Epoch 216/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.9850 - val_loss: 137.3144\n",
      "Epoch 217/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 141.8241 - val_loss: 137.8614\n",
      "Epoch 218/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3102 - val_loss: 137.1902\n",
      "Epoch 219/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 142.0138 - val_loss: 137.4717\n",
      "Epoch 220/400\n",
      "1784/1784 [==============================] - 8s 4ms/step - loss: 142.2746 - val_loss: 138.7068\n",
      "Epoch 221/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4590 - val_loss: 137.2823\n",
      "Epoch 222/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4619 - val_loss: 138.2381\n",
      "Epoch 223/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2940 - val_loss: 137.9844\n",
      "Epoch 224/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.0927 - val_loss: 138.1329\n",
      "Epoch 225/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.5753 - val_loss: 138.0386\n",
      "Epoch 226/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.7654 - val_loss: 137.6112\n",
      "Epoch 227/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0982 - val_loss: 137.5118\n",
      "Epoch 228/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5999 - val_loss: 137.4443\n",
      "Epoch 229/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2817 - val_loss: 137.9437\n",
      "Epoch 230/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1246 - val_loss: 137.7442\n",
      "Epoch 231/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1683 - val_loss: 137.7482\n",
      "Epoch 232/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1480 - val_loss: 138.3247\n",
      "Epoch 233/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4449 - val_loss: 137.6619\n",
      "Epoch 234/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1579 - val_loss: 138.5413\n",
      "Epoch 235/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.7044 - val_loss: 137.9219\n",
      "Epoch 236/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.5342 - val_loss: 136.8555\n",
      "Epoch 237/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.9591 - val_loss: 137.5541\n",
      "Epoch 238/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.8993 - val_loss: 137.6875\n",
      "Epoch 239/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4226 - val_loss: 136.7631\n",
      "Epoch 240/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.7762 - val_loss: 138.2290\n",
      "Epoch 241/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.6364 - val_loss: 138.2802\n",
      "Epoch 242/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2219 - val_loss: 138.3285\n",
      "Epoch 243/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4238 - val_loss: 136.6457\n",
      "Epoch 244/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4842 - val_loss: 137.8008\n",
      "Epoch 245/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.9730 - val_loss: 136.9144\n",
      "Epoch 246/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4050 - val_loss: 137.5078\n",
      "Epoch 247/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3385 - val_loss: 139.0216\n",
      "Epoch 248/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.7066 - val_loss: 137.8158\n",
      "Epoch 249/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1178 - val_loss: 136.7986\n",
      "Epoch 250/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.5701 - val_loss: 138.0149\n",
      "Epoch 251/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3476 - val_loss: 137.6374\n",
      "Epoch 252/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4904 - val_loss: 136.8063\n",
      "Epoch 253/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.7231 - val_loss: 137.9301\n",
      "Epoch 254/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0833 - val_loss: 137.3139\n",
      "Epoch 255/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3854 - val_loss: 137.9650\n",
      "Epoch 256/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.6029 - val_loss: 137.6983\n",
      "Epoch 257/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2391 - val_loss: 138.6465\n",
      "Epoch 258/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4892 - val_loss: 138.3611\n",
      "Epoch 259/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.6772 - val_loss: 138.9562\n",
      "Epoch 260/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.9578 - val_loss: 138.5047\n",
      "Epoch 261/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 143.1215 - val_loss: 138.4393\n",
      "Epoch 262/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 143.1494 - val_loss: 138.1837\n",
      "Epoch 263/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4172 - val_loss: 138.1678\n",
      "Epoch 264/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2681 - val_loss: 137.4461\n",
      "Epoch 265/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4102 - val_loss: 136.4389\n",
      "Epoch 266/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0908 - val_loss: 137.3271\n",
      "Epoch 267/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.9496 - val_loss: 137.1592\n",
      "Epoch 268/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3082 - val_loss: 137.4776\n",
      "Epoch 269/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5845 - val_loss: 138.0529\n",
      "Epoch 270/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.5150 - val_loss: 137.5093\n",
      "Epoch 271/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1866 - val_loss: 138.6885\n",
      "Epoch 272/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4972 - val_loss: 137.3441\n",
      "Epoch 273/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1125 - val_loss: 137.3401\n",
      "Epoch 274/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3548 - val_loss: 137.3651\n",
      "Epoch 275/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.8215 - val_loss: 136.5560\n",
      "Epoch 276/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2135 - val_loss: 137.6351\n",
      "Epoch 277/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3176 - val_loss: 138.3885\n",
      "Epoch 278/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.8727 - val_loss: 136.8432\n",
      "Epoch 279/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.5650 - val_loss: 137.2066\n",
      "Epoch 280/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.3541 - val_loss: 138.3784\n",
      "Epoch 281/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.2560 - val_loss: 136.9847\n",
      "Epoch 282/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2311 - val_loss: 137.6850\n",
      "Epoch 283/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2547 - val_loss: 137.2924\n",
      "Epoch 284/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4464 - val_loss: 137.0860\n",
      "Epoch 285/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4960 - val_loss: 138.1766\n",
      "Epoch 286/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0835 - val_loss: 138.0456\n",
      "Epoch 287/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.7104 - val_loss: 138.4498\n",
      "Epoch 288/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0016 - val_loss: 138.7439\n",
      "Epoch 289/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1475 - val_loss: 137.8990\n",
      "Epoch 290/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.7237 - val_loss: 137.9774\n",
      "Epoch 291/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3629 - val_loss: 137.8875\n",
      "Epoch 292/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2930 - val_loss: 138.1574\n",
      "Epoch 293/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3837 - val_loss: 137.2256\n",
      "Epoch 294/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2282 - val_loss: 137.1207\n",
      "Epoch 295/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.3468 - val_loss: 137.3656\n",
      "Epoch 296/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1053 - val_loss: 138.3989\n",
      "Epoch 297/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.7761 - val_loss: 137.8753\n",
      "Epoch 298/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.7117 - val_loss: 136.3539\n",
      "Epoch 299/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.6600 - val_loss: 137.4776\n",
      "Epoch 300/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.8953 - val_loss: 136.8805\n",
      "Epoch 301/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1907 - val_loss: 136.4336\n",
      "Epoch 302/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2934 - val_loss: 137.2385\n",
      "Epoch 303/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.8815 - val_loss: 136.4146\n",
      "Epoch 304/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.7658 - val_loss: 136.7381\n",
      "Epoch 305/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2315 - val_loss: 137.1625\n",
      "Epoch 306/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1118 - val_loss: 137.9658\n",
      "Epoch 307/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.7647 - val_loss: 136.5441\n",
      "Epoch 308/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.7903 - val_loss: 137.1026\n",
      "Epoch 309/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.9613 - val_loss: 137.1444\n",
      "Epoch 310/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.8547 - val_loss: 136.5832\n",
      "Epoch 311/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.9967 - val_loss: 136.9029\n",
      "Epoch 312/400\n",
      "1784/1784 [==============================] - 6s 4ms/step - loss: 142.0200 - val_loss: 137.5684\n",
      "Epoch 313/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1276 - val_loss: 137.8601\n",
      "Epoch 314/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 141.7827 - val_loss: 138.0984\n",
      "Epoch 315/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3271 - val_loss: 137.3712\n",
      "Epoch 316/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1885 - val_loss: 137.8505\n",
      "Epoch 317/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.8383 - val_loss: 137.4734\n",
      "Epoch 318/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0817 - val_loss: 137.6972\n",
      "Epoch 319/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0460 - val_loss: 136.5611\n",
      "Epoch 320/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0769 - val_loss: 138.1583\n",
      "Epoch 321/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0396 - val_loss: 137.9184\n",
      "Epoch 322/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0856 - val_loss: 137.0221\n",
      "Epoch 323/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0572 - val_loss: 136.4317\n",
      "Epoch 324/400\n",
      "1784/1784 [==============================] - 6s 4ms/step - loss: 142.1952 - val_loss: 137.5239\n",
      "Epoch 325/400\n",
      "1784/1784 [==============================] - 9s 5ms/step - loss: 141.7841 - val_loss: 136.8541\n",
      "Epoch 326/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.2538 - val_loss: 137.0207\n",
      "Epoch 327/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.7610 - val_loss: 139.8133\n",
      "Epoch 328/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.5842 - val_loss: 137.3470\n",
      "Epoch 329/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0057 - val_loss: 138.5479\n",
      "Epoch 330/400\n",
      "1784/1784 [==============================] - 6s 4ms/step - loss: 142.5341 - val_loss: 137.0619\n",
      "Epoch 331/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.9624 - val_loss: 137.4492\n",
      "Epoch 332/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4381 - val_loss: 137.4431\n",
      "Epoch 333/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0525 - val_loss: 137.9304\n",
      "Epoch 334/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.9542 - val_loss: 137.0629\n",
      "Epoch 335/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0916 - val_loss: 137.8487\n",
      "Epoch 336/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4219 - val_loss: 137.9581\n",
      "Epoch 337/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5120 - val_loss: 138.4075\n",
      "Epoch 338/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4381 - val_loss: 137.7414\n",
      "Epoch 339/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3645 - val_loss: 136.4031\n",
      "Epoch 340/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2356 - val_loss: 137.8156\n",
      "Epoch 341/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5008 - val_loss: 137.8695\n",
      "Epoch 342/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2270 - val_loss: 137.7157\n",
      "Epoch 343/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.8906 - val_loss: 136.6282\n",
      "Epoch 344/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0283 - val_loss: 137.2832\n",
      "Epoch 345/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.3725 - val_loss: 136.7690\n",
      "Epoch 346/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.5438 - val_loss: 137.3569\n",
      "Epoch 347/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3751 - val_loss: 137.6837\n",
      "Epoch 348/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.9506 - val_loss: 137.6601\n",
      "Epoch 349/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.8840 - val_loss: 137.9977\n",
      "Epoch 350/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0173 - val_loss: 137.5448\n",
      "Epoch 351/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5906 - val_loss: 138.7007\n",
      "Epoch 352/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.0217 - val_loss: 137.0148\n",
      "Epoch 353/400\n",
      "1784/1784 [==============================] - 10s 5ms/step - loss: 142.0871 - val_loss: 138.0505\n",
      "Epoch 354/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 141.8026 - val_loss: 136.5278\n",
      "Epoch 355/400\n",
      "1784/1784 [==============================] - 11s 6ms/step - loss: 142.4383 - val_loss: 136.7012\n",
      "Epoch 356/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 141.6474 - val_loss: 137.4535\n",
      "Epoch 357/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 141.6062 - val_loss: 135.9748\n",
      "Epoch 358/400\n",
      "1784/1784 [==============================] - 6s 4ms/step - loss: 141.8012 - val_loss: 136.1347\n",
      "Epoch 359/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 141.7754 - val_loss: 137.4741\n",
      "Epoch 360/400\n",
      "1784/1784 [==============================] - 15s 8ms/step - loss: 141.5781 - val_loss: 137.1119\n",
      "Epoch 361/400\n",
      "1784/1784 [==============================] - 8s 4ms/step - loss: 141.8860 - val_loss: 136.6362\n",
      "Epoch 362/400\n",
      "1784/1784 [==============================] - 12s 7ms/step - loss: 141.8506 - val_loss: 135.9060\n",
      "Epoch 363/400\n",
      "1784/1784 [==============================] - 19s 11ms/step - loss: 142.5903 - val_loss: 136.9987\n",
      "Epoch 364/400\n",
      "1784/1784 [==============================] - 18s 10ms/step - loss: 142.7929 - val_loss: 138.3699\n",
      "Epoch 365/400\n",
      "1784/1784 [==============================] - 10s 6ms/step - loss: 142.8139 - val_loss: 138.1998\n",
      "Epoch 366/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.5835 - val_loss: 138.2113\n",
      "Epoch 367/400\n",
      "1784/1784 [==============================] - 6s 4ms/step - loss: 142.4797 - val_loss: 139.1593\n",
      "Epoch 368/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.0006 - val_loss: 136.3199\n",
      "Epoch 369/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 142.1473 - val_loss: 136.9587\n",
      "Epoch 370/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 141.8121 - val_loss: 137.3973\n",
      "Epoch 371/400\n",
      "1784/1784 [==============================] - 7s 4ms/step - loss: 141.7262 - val_loss: 138.9851\n",
      "Epoch 372/400\n",
      "1784/1784 [==============================] - 8s 4ms/step - loss: 142.4007 - val_loss: 137.6710\n",
      "Epoch 373/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.2389 - val_loss: 137.4132\n",
      "Epoch 374/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 141.7140 - val_loss: 137.1824\n",
      "Epoch 375/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.1623 - val_loss: 136.8950\n",
      "Epoch 376/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0631 - val_loss: 137.2971\n",
      "Epoch 377/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.8393 - val_loss: 137.1500\n",
      "Epoch 378/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.7450 - val_loss: 136.3802\n",
      "Epoch 379/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2006 - val_loss: 138.0026\n",
      "Epoch 380/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1371 - val_loss: 137.8853\n",
      "Epoch 381/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2548 - val_loss: 137.2396\n",
      "Epoch 382/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4966 - val_loss: 138.4038\n",
      "Epoch 383/400\n",
      "1784/1784 [==============================] - 6s 3ms/step - loss: 142.4965 - val_loss: 136.8809\n",
      "Epoch 384/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0931 - val_loss: 137.0169\n",
      "Epoch 385/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.1699 - val_loss: 136.8625\n",
      "Epoch 386/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.4248 - val_loss: 137.3823\n",
      "Epoch 387/400\n",
      "1784/1784 [==============================] - 6s 4ms/step - loss: 142.2992 - val_loss: 136.4308\n",
      "Epoch 388/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.9113 - val_loss: 137.8264\n",
      "Epoch 389/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2905 - val_loss: 137.5728\n",
      "Epoch 390/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.4237 - val_loss: 137.0889\n",
      "Epoch 391/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.8001 - val_loss: 137.0425\n",
      "Epoch 392/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3660 - val_loss: 136.9236\n",
      "Epoch 393/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.9539 - val_loss: 138.2403\n",
      "Epoch 394/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0097 - val_loss: 137.3828\n",
      "Epoch 395/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.3659 - val_loss: 138.2002\n",
      "Epoch 396/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.5781 - val_loss: 137.5658\n",
      "Epoch 397/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.0717 - val_loss: 136.6795\n",
      "Epoch 398/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 141.8981 - val_loss: 136.3443\n",
      "Epoch 399/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2407 - val_loss: 137.5300\n",
      "Epoch 400/400\n",
      "1784/1784 [==============================] - 5s 3ms/step - loss: 142.2670 - val_loss: 137.5355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f45c07e80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=400, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcef8b9",
   "metadata": {},
   "source": [
    "It will take some time because of a huge number of samples and epochs and will output the ‘loss’ and ‘val_loss’ of each sample as below.\n",
    "After the training is complete, let us visualize our model’s losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bea8194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_losses = pd.DataFrame(model.history.history)\n",
    "model_losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0ff1f",
   "metadata": {},
   "source": [
    "As we can see our model is having absolutely perfect behavior!  \n",
    "\n",
    "Step 6: Predictions!\n",
    "\n",
    "Here we come to the final part of our project where we will be predicting our X_test. Then we will create a dataframe that would show us the actual values and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f374c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879/879 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.969944</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.677502</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.969944</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.921875</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.281471</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.233898</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.118122</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.765152</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.213978</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.790630</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predict  Actual\n",
       "0  50.969944    47.0\n",
       "1  56.677502    53.0\n",
       "2  50.969944    56.0\n",
       "3  51.921875    52.0\n",
       "4  48.281471    20.0\n",
       "5  55.233898    47.0\n",
       "6  49.118122    26.0\n",
       "7  51.765152    43.0\n",
       "8  52.213978    55.0\n",
       "9  48.790630    48.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "sample = pd.DataFrame(predictions,columns=['Predict'])\n",
    "sample['Actual']=y_test\n",
    "sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e3a55",
   "metadata": {},
   "source": [
    "As we can see, our model is predicting quite well. It is giving us almost similar scores. To find out more accurately the difference between actual and predicted scores, performance metrics will show us the error rate using mean_absolute_error and mean_squared_error from sklearn.metrics \n",
    "\n",
    "# Performance Metrics! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "393e1588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.23479377896923"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "  \n",
    "mean_absolute_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5361545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.727558088415382"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
